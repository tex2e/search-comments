"/" can't be in filenames :)
"BG" stands for background.
"essential for building Debian packages"
# Run this script from the root of the docker repository to query project stats useful to the maintainers.
# Tests in a meteor project
# garbage collection if not, next time warp will pick up variables from this run remember, there's no sub shell
## TODO: - contrib/ - module_utils that are py2.6+
## testsuite: skip nested quoting test
### END LIBTOOL TAG CONFIG: disable-shared BEGIN LIBTOOL TAG CONFIG: disable-static
### END LIBTOOL TAG CONFIG: disable-static Local Variables: mode:shell-script sh-indentation:2 End:
##### Non read-only tests
##### Read-only tests
##### Universal compaction tests.
########################################################## 4.8.1 dependencies                    #
########################################################## 4.9.x dependencies                    #
###################################################################
###############################################################################
############################################################################### Compute a hash that can be used as a unique repo schema identifier.
##-begin-npm-completion-###
##-end-npm-completion-###
(Can't strip too much because we do need node to be able to load objects like fibers.node.)
(Expression based on build.js in fibers source.)
(See gh-2765, gh-2768.)  Using 'pip install' also has the advantage that it tests that numpy is 'pip install' compatible, see e.g. gh-2766...
(optional) move to a new line
* Private attributes of other objects are not: self.other._private
* `atom-args`: A space-separated list of positional arguments to pass to Atom.
* `atom-path`: The path to the `Atom` binary.
* private attributes of ourself are okay: self._private.
- Error if docker versions are not equal.
- Error if running 32-bit posix tools.
- The VERSION file, at the root of the repository, should exist, and will be used as Docker binary version and package version.
- The hash of the git commit will also be included in the Docker binary, with the suffix -unsupported if the repository isn't clean.
- The right way to call this script is to invoke "make" from your checkout of the Docker repository.
- The script is intended to be run inside the docker container specified in the Dockerfile at the root of the source.
- This is done just by looking for those tokens and setting the "flag".
- Tidy up of images and containers.
- We make sure to still print things for the removed lines, to keep line numbers consistent to ease debugging.
- btrfs-tools is missing "ioctl.h" (too old), so it's useless (since kernels on precise are old too, just skip btrfs entirely)
- libdevmapper-dev is missing critical structs (too old)
./ldb needs to be avaible to be executed.
2048 is the max for non root users on Mac
:    Fetch the newest version of Homebrew and all formulae from GitHub using :     `git`(1).
: :    If `--merge` is specified then `git merge` is used to include updates :      (rather than `git rebase`).
@github.com/mfaerevaag/wd version
A base image with build tools and a user account
A fraction is less than an integer.
A libtool-controlled library.
A libtool-controlled object.
A shell script to load some pre generated data file to a DB using ldb tool ./ldb needs to be avaible to be executed.
A shell script to verify DB generated by generate_random_db.sh cannot opened and read correct data.
A small script for comparing IR for unit tests from before and after a change to the JIT.
A standard non-PIC object
A word about this shell script:
Accelerate Makefiles generation
Accept any command-line options.
Accept the current argument as the source file.
Add PIC object to the list of files to remove.
Add a file to the app that shuts it down immediately
Add all defined plugins to fpath.
Add in all the interfaces that we are compatible with.
Add libc to deplibs on all other systems if necessary.
Add nested executables to bundle dir so we have complete set of them available, but only if the native OS/ARCH is the same as the OS/ARCH of the build target
Add non-PIC object to the list of files to remove.
Add our own program objects to the symbol list.
Add redirect at /builds/info for URL-backwards-compatibility
Add server-tests path to root directory to get test file directory
Add the "lib" prefix for modules if required
Add the arguments to base_compile.
Add the color to the diff.
Add the containers module Note well-1: the SLE machine must already be registered against SUSE Customer Center Note well-2: the `-r ""` is required to workaround a known issue of SUSEConnect
Add the dll search path components to the executable PATH
Add the libdir to current_libdirs if it is the destination.
Add the search paths of all dependency libraries
Add the symbol object into the linking commands.
Aesthetically quote it.
Aesthetically quote the argument.
Again, this script is for demonstration purpose.
Again, we only want to link against shared libraries
Again, writing regexps to a file.
All functions, variables which must exist are put in this file.
All subsequent reloadable object files will link in the last one created.
All the library-specific variables (install_libdir is set above).
Allow error messages only from the first compilation.
Allow the use of GNU shtool's install command.
Also make sure to update MONGO_VERSION in generate-dev-bundle.ps1.
Also make sure to update NODE_VERSION in generate-dev-bundle.ps1.
Also need to implement whitelist for certain things like bundled libraries that violate this.
Also used by the default 'make install' in node to point npm at the newly installed node, rather than the first one in the PATH, which would be the default otherwise.
Always ask for I/O statistics to be measured.
Amend to last commit if user do the post-commit format check
An additional grant of patent rights can be found in the PATENTS file in the same directory.
An image for each of the io.js versions we want to test with that version installed and the latest npm
An image for each of the node versions we want to test with that version installed and the latest npm
An image on top of the base containing clones of repos we want to use for testing
An integer is greater than a fraction.
Any other switches will be passed through to `Atom`.
Anything else should be a program.
Appears we had some issues with certificates on Travis.
Append the command to create the export file.
Append the name of the PIC object to the libtool object file.
Append the name of the non-PIC object the libtool object file.
Assume this is the tagged configuration we want.
Assumes GNU versions of utilities in PATH.
Assumes old tracelogs are in *.log.old and new ones are in *.log.
At the moment a cython generated code produces a warning about '-2147483648L', but the code seems to compile OK.
Avoid inline document here, it may be left over
BEGIN LIBTOOL TAG CONFIG: disable-shared
Backslashes separate directories on plain windows
Based on the Bash documentation example.
Baseline Qt configuration.
Be Bourne compatible (taken from Autoconf:_AS_BOURNE_COMPATIBLE).
Be nice, post SIGTERM first.
Blanks in the command may have been stripped by the calling shell, but not from the CC environment variable when configure was run.
Break out early, otherwise skipped_export may be set to false by a later but shorter cmd.
Build fails on mac right now with C++11
Build into own virtualenv We therefore control our own environment, avoid travis' numpy
Build only for release (no debugging support)
Building a libtool convenience library.
Building outside of a git repo, use system time instead.
Bundle React Native app's code and image assets.
Bundles should be available for the VERSION string passed as argument.
But we must not use pic_flag when linking with -static.
But we'll never go from static-only to shared-only.
But, then there is irix which has an extra 1 added just for fun
By default we'll run all the tests.
CHECK ME:  I think I busted this.
CI Integrity check - ensure we are using the same version of go as present in the Dockerfile
Calculate the filename of the output object if compiler does not support -o with -c
Calculate the version variables.
Call git grep to find all js files with the appropriate comment tags, and only then pass it to JSDoc which will parse the JS files.
Can't do until all Azure nodes are updated - Error if go versions are not equal.
Can't do until all Azure nodes are updated.
Can't do until all Azure nodes on the latest version - Make sure we are not running as local system.
Can't find it, oh well...
Can't use summarize_result here.
Cancel upgrade if git is unavailable on the system
Cancel upgrade if the current user doesn't have write permissions for the oh-my-zsh directory.
Cannot resume." "HTTP/1.1 416 Requested Range Not Satisfiable"
Causes problems with __ctype
Change into that dir because we expect that
Change into that directory
Change the cli shebang to point at the specified node Useful for when the program is moved around after install.
Change the help message to a mode-specific one.
Check access to the bucket.
Check argparse, a library that clang-format-diff.py requires.
Check clang-format-diff.py
Check for an acceptable number of warnings.
Check for lsb_release command existence, it usually exists in forked distros
Check if any of the arguments is a wrapper script.
Check if the `-u` option is supported
Check if the command has exited successfully, it means we're in a forked distro
Check if there's a prebuilt binary and if so just fetch that.
Check if there's anything to be done, exit early if not.
Check if this is a forked Linux distro
Check if this script has already been added to pre-commit hook.
Check is here for local runs from Jenkins machines just in case not in the right directory where the repo is cloned.
Check that each of the things are valid numbers.
Check that the site has been built
Check the Linux box is running a matching version of docker
Check the format of last commit
Check the format of uncommitted lines,
Check the variables that should have been set.
Check to make sure the proper number of each kind of file is there.
Check to see if the archive will have undefined symbols.
Check to see that each library is installed.
Check to see that the destination is a directory.
Check to see that this really is a libtool archive.
Check to see that this really is a libtool object.
Check whether tagname contains only valid characters
Checkout and build mongodb.
Checkout and build your new hhvm, then: ./test/run -l -m jit ./test/quick ./test/tools/compare-ir.sh
Chrome uses these empty locale directoires for its helper executable bundles, which do not otherwise require any direct Cocoa locale support.
Clean up some bulky stuff.
Clean up the generated files.
Clear the reloadable object creation command queue and initialize k to one.
Clear the version info if we defaulted, and they specified a release.
Cloning latest 'master' of Linenoise
Cocoa only, ignore Carbon
Collect dlpreopened libraries
Compare two fractions.
Compare two integers.
Compiler inserts libc in the correct place for threads to work
Configurable libraries.
Consequently, we have to totally remove the  generated files and put stubs in place, before calling "go run" again to recreate them.
Consider the longer to be less.
Copy mongodb distribution information
Create a base CentOS Docker image.
Create a libtool object file (analogous to a ".la" file), but don't create it if we're doing a dry run.
Create a temporary build dir and make sure we clean it up.
Create an invalid libtool object if no PIC, so that we don't accidentally link it into a program.
Create links to the real library.
Create one if there is no X window yet.
Create the object directory.
Create the old-style object.
Currently the code has many places where we're violating this test so we need to clean up the code before we can enable this.
Cygdrive paths don't play well with go build -o.
Darwin ld doesn't like 0 for these options...
Deduce the name of the destination old-style object file.
Deduce the name of the old-style object file.
Default to old behavior
Default to our custom QPA platform
Defaults for choices between bundled/system libraries.
Define NVM_DIR and source the nvm.sh setup script
Define a set of benchmarks.
Delay between posting the SIGTERM signal and destroying the process by SIGKILL.
Delete any .DS_Store files for our OS X friends.
Delete any leftover library objects.
Delete the generated files.
Delete the libtool libraries and symlinks.
Delete the old objects.
Delete the old output file.
Delete the old output files.
Delete the old symlinks, and create new ones.
Demonstrate that h2tp can handle file- and directory-name components that contain spaces.
Detect the user's operating system
Determine the prefix the user has applied to our future dir.
Determine the type of output
Die if any command dies, error on undefined variable expansions.
Diff against the old results
Directory that this library needs to be installed in:
Disable D-Bus feature
Disable theming integration with Gtk+
Disable this feature.
Discard the --no-reexec flag, and continue.
Discover the nlist of each of the dlfiles.
Display the authors list and write it to the file
Display what would be done.
Do NOT CHANGE this if you don't know what you're doing -- see https://code.google.com/p/chromium/wiki/UpdatingClang Reverting problematic clang rolls is safe, though.
Do a symbolic link so that the libtool archive can be found in LD_LIBRARY_PATH before the program is installed.
Do a test to see if this is a libtool program.
Do a test to see if this is really a libtool program.
Do each command in the archive commands.
Do each command in the finish commands.
Do each command in the old_postuninstall commands.
Do each command in the postinstall commands.
Do each command in the postuninstall commands.
Do each installation.
Do each of the archive commands.
Do in-place format adjustment.
Do not bother doing anything if just a dry run
Do not include libc due to us having libc/libc_r.
Do not include libc_r directly, use -pthread flag.
Do the single finish_eval.
Do the static libraries later.
Docker mounts tmpfs at /dev and procfs at /proc so we can remove them
Doing this in parallel is racy, but the absolute worst that can happen is we'll end up with some garbled text inside a .noserver file.
Don't allow lazy linking, it breaks C++ global constructors
Don't allow the user to place us outside of our expected location b/c this prevents finding dependent libraries that are installed to the same prefix.
Don't allow undefined symbols.
Don't build any examples
Don't build the tools
Don't build with the demos
Don't check for shared/static.
Don't error if the file doesn't exist and rm -f was used.
Don't generate the documentation
Don't link with libc until the a.out ld.so is fixed.
Don't print as many progress indicators
Don't report commands used mostly by our scripts and not users.
Don't report non-official commands.
Don't send or store any personally identifiable information.
Don't test for the "default" C tag, as we know, it's there, but not specially marked.
Don't try to do a `git fetch` that may take longer than expected.
Don't use C++ exception
Double-quote args containing other shell metacharacters.
Download BrowserStackLocal binary.
Either here, or in the teardown script.
Eliminate all temporary directories.
Else, enable and cache completions to the desired file.
Else, suggest the user do so manually.
Emacs shell doesn't need readline and interprets the ANSI characters as garbage.
Enable the optional repository
Enable tracing and exit on first failure
Enable use of as many system libraries as possible.
Encode it into a variable for safe keeping.
End of Shell function definitions  Darwin sucks
Ensure Gradle Wrapper is executable
Ensure the proper AWS environment variables are set
Ensure the proper Fastly keys are set
Ensure we have s3cmd installed
Error occurred in the first compile.
Evaluate the configuration.
Example: require_tool gcc 4.6 Use GCC environment variable if defined instead of lookup for the tool in the environment.
Execute a set of benchmarks to cover variety of scenarios.
Exit here if they wanted silent mode.
Exit if Atom can't be found
Exit if we aren't doing a library object file.
Explicitly compile with SSL support, so build will fail if headers are missing
Explicitly compile with support for OpenSSL enabled, so the build will fail if headers are missing.
Export our shlibpath_var if we have one.
Export the shlibpath_var.
Extra step to ensure the static libraries are found
Extract -R from dependency_libs
Extract latest commit log info and prepare "README.md" content
Extract subdirectory from the argument.
FG_MBWRITEPERSEC - write rate limit in MB/second for tests like overwrite where stats are reported for the write threads.
FIXME: remove this flag sometime in the future.
FIXME: should reinstall the best remaining shared library.
FIXME: these two pipelines are reading and writing to the same file.
Failing to do so causes compinit() calls to fail with "command not found: compdef" errors for users with insecure umasks (e.g., "002", allowing group writability).
Fast installation is not supported
Fetch right version of gcov
Fibers ships with compiled versions of its C code for a dozen platforms.
Figure out destination file name, if it wasn't already specified.
Figure out the SHORT hostname
Figure out why this happens.
Files to dlopen/dlpreopen
Finalize command for both is simple: just hardcode it.
Find all gcno files to generate the coverage report
Find all interdependent deplibs by searching for libraries that are linked more than once (e.g. -la -lb -la)
Find how many commits we are ahead/behind our upstream
Find the directory that this script lives in.
Find the relevant object directory and library name.
First ensure that this is being run from the basedir (i.e. dirname of script is .)
First prepare all scripts (build, commit, tag, ...), so we are sure everything is all right
First prepare all scripts (build, test, commit, tag, ...), so we are sure everything is all right
First, .php files are included with their open tags stripped.
First, compute the expected output using regular HHVM execution
First, we install the modules that are dependencies of tools/server/boot.js: the modules that users of 'meteor bundle' will also have to install.
Follow Location: headers, and fail on errors
Follow symbolic links until we get to the real thisdir.
Fontconfig for better font matching
Fontconfig is essential on non-Darwin Unix.
Fontconfig is not required on Darwin (we use Core Text for font enumeration) and is reported to not work correctly.
For Linuxbrew's analytics.
For debugging, comment out the trap line.
For how it is generated, see `hack/generate-authors.sh`.
For more details on the changes see the blog post listed below.
For now, use our fork with https://github.com/npm/npm/pull/5821
For now, we need to specify -no-undefined on the libtool link line when we can be certain that all symbols are satisfied, otherwise we get a static library.
For parallelizing the bootstrapping process, e.g. qmake and friends.
For universal compaction, these level0_* options mean total sorted of runs in LSM.
Force UTF-8 to avoid encoding issues for users with broken locale settings.
Force remove all containers based on a previously built image with this commit
Force remove any container with this commithash as a name
Force remove the image if it exists
Force use of as many bundled libraries as possible.
Freetype for text rendering
From within the source directory...
Furthermore brandelf is used to make the lib and binary compatible with older unix/linux machines that don't know the new Linux ELF ABI.
Gather all diagnostic identifiers.
Generate Go code listing errors and other #defined constant values (ENAMETOOLONG etc.), by asking the preprocessor about the definitions.
Generate a minimal filesystem for CRUX/Linux and load it into the local docker as "cruxlinux" requires root and the crux iso (http://crux.nu)
Generate a minimal filesystem for archlinux and load it into the local docker as "archlinux" requires root
Generate a very minimal filesystem based on busybox-static, and load it into the local docker under the name "busybox".
Generate four random files.
Generate the html report.
Get Connect and start it
Get a list of authors ordered by number of commits and remove the commit count column
Get the absolute pathname.
Get the commit has and verify we have something
Get the compilation command and the source file.
Get the full path of this script
Get the most recently committed files.
Get the name of the library object.
Get the parent directory of where this script is and change into our website directory
Get the parent directory of where this script is.
Get the real and link names of the library.
Get the upstream release info
Get the version from the command line
Get the version from the remote node.
Getting valid data requires a number of iterations and having an ability to run the test separately from rest of the benchmarks helps.
Given that compact benchmark doesn't output regular statistics then we'll just use the time command to measure how long this step takes.
Go through the arguments, transforming them on the way.
Go to GhostDriver (Java) Tests
Gone through all deplibs.
Hacky way of disabling fbmake's pre_command.
Handle -dlopen flags immediately.
Handle the remaining objects by creating one last reloadable object file.
Hardcode the library path.
Hardcode the library paths
Has to be run from project root directory.
Hello Chet, please find attached a "little easier"  :-)  to comprehend time-out example.
Helper for running TestExt from an fbmake build.
Helper function that is meant to be called from __git_ps1.
Here we assume that one of hardcode_direct or hardcode_minus_L is not unsupported.
Highlight the insertion/deletion from the clang-format-diff.py's output
However, greadlink is fine, so Solaris can join the party, too.
However, should absolutely not be a problem if built natively, so nit-picking.
I think release should show up in the -l (ie -lgmp5) so we don't want to add it in twice.
I think this is a good way to load.
I would guess that would be a bug.
I'm not sure if I'm treating the release correctly.
ICU support in QtBase is reported to be unnecessary for Darwin.
INSTALL: * put something like this in your .bashrc/.zshrc: .
If -module or -export-dynamic was specified, set the dlname.
If a disable-shared tag is given, we'll fallback to a static-only configuration.
If clang_format_diff.py command is not specfied, we assume we are able to access directly without any path.
If completion insecurities exist, warn the user without enabling completions.
If given, STRING is the basename for that directory.
If it is, it will not operate correctly.
If it won't happen then empty output from grep when searching for "Sum" will cause syntax errors.
If libtool objects are unsupported, then we need to preload.
If mktemp works, use that first and foremost
If no command line arguments then run for 24 threads.
If no make is found, then just execute the necessary commands.
If not set, fall back to "master".
If readlink isn't available, then this is just too tricky.
If sqlite3.h doesn't exist under /usr/include, check /usr/local/include also just in case (e.g. FreeBSD Ports installs it under the directory)
If the PIC object exists, use it instead.
If the file is missing, and there is a .exe on the end, strip it because it is most likely a libtool script we actually want to install
If the library has no export list, then create one now
If the library was installed with an old release of libtool, it will not redefine variables installed, or shouldnotlink
If the previous option needed an argument, then skip it.
If the previous option needs an argument, assign it.
If the signal is blocked, then the subsequent SIGKILL (9) terminates it.
If the user specified any rpath flags, then add them.
If the user specifies -o file.o, it is replaced with file.lo
If the wait flag is set, don't exit this process until Atom tells it to.
If there are failures, their test filenames will be printed to stdout.
If there is no directory component, then add one.
If there is no dlname, no dlopen support or we're linking statically, we need to preload.
If there is no dlopen support or we're linking statically, we need to preload.
If there was a directory component, then change thisdir.
If there's no bash, then don't even try to clean
If there's no uncommitted changes, we assume user are doing post-commit format check, in which case we'll check the modified lines from latest commit.
If these fail, game over.
If this fails, it's not such a big deal.
If this is not what you need, feel free to make your own scripts.
If this is too large then the non-writer threads can get starved.
If this user's login shell is not already "zsh", attempt to switch.
If this variable is set in any of the actions, the command in it will be execed at the end.
If using bash 3.1 which doesn't support --rfc-3389, eg Windows CI
If we cannot find lcov in this machine, we'll simply skip this step.
If we have no mode, but dlfiles were specified, then do execute mode.
If we have whole_archive_flag_spec, we want to use save_libobjs as it was before whole_archive_flag_spec was expanded, because we can't assume the linker understands whole_archive_flag_spec.
If we put the line we're generating into this file, then the linter will think the generator itself is generated.
If we're not in dry-run mode, bomb out on failure
If you compile php using --with-cdb the internal functions will be used and no  external library is used so that this script is not necessary.
If you find it suitable, feel free to include anywhere: the very same logic as in the original examples/scripts, a little more transparent implementation to my taste.
If you have not, please install them first.
If you would like a colored hint about the current dirty state, set GIT_PS1_SHOWCOLORHINTS to a nonempty value.
If you would like to see if there're untracked files, then you can set GIT_PS1_SHOWUNTRACKEDFILES to a nonempty value.
If you would like to see more information about the identity of commits checked out as a detached HEAD, set GIT_PS1_DESCRIBE_STYLE to one of these values:
Ignore errors (it might already exist).
Ignore errors from strip.
Ignore the translations
In PC mode PS1 always needs to be set
In addition, if you set GIT_PS1_SHOWDIRTYSTATE to a nonempty value, unstaged (*) and staged (+) changes will be shown next to the branch name.
In case of error, message is written on error output.
In case the old package URL is still being used
In level-based compaction, it means number of L0 files.
In other words: DO NOT CALL THIS SCRIPT DIRECTLY.
Infer the operation mode.
Initializes Oh My Zsh add a function path
Install (i.e. copy) a libtool object.
Install core packages
Install nvm for this shell
Install the binary that we compiled earlier.
Install the libtool object if requested.
Install the old object if enabled.
Install the pseudo-library for information purposes.
Install the shared library and build the symlinks.
Instead, add this to base_compile
Internal variable for brew's use, to differentiate from user-supplied setting
Interval between checks if the process is still alive.
It backslashifies metacharacters that are still active within double-quoted strings.
It comes without any warranty, to the extent permitted by applicable law.
It injects color codes into the appropriate gitstring variables used to build a gitstring.
It is a libtool convenience library, so add in its objects.
It is also expected to be safe to use the system libjpeg on non-Darwin.
It is needed because there is some dependency between the generated code and the other classes.
It is not bundled and links with the system freetype, so it is useless to avoid the system freetype or its dependencies.
It is still crash safe and the client can discover where to restart a load after a crash.
It looks like bumping to 14.0.6 will help.
It must work everywhere, including on systems that lack a /bin/bash, map 'sh' to ksh, ksh97, bash, ash, or zsh, and potentially have either a posix shell or bourne shell living at /bin/sh.
It then changes to that directory and creates subdirectories for each locale_dir passed on the command line.
It uses the latest g++ compiler and also uses jemalloc
It would break on at least Digital Unix and AIX.
It'll also stub "node-pre-gyp".
It'll download the relevant parts of "node-inspector" used by "nuclide-debugger-node", and its dependencies.
It's actually not that bad.
It's an error (unlike with rm -rf) if they don't exist, because that might mean it moved somewhere else and we should update the delete line.
Just accumulate the unique libdirs.
Just add the directory containing the .lo file.
Just implementing what was already the behavior.
Just move the object if needed
Just move the object if needed, then go on to compile the next one
Just print a warning and add the library to dependency_libs so that the program can be linked against the static library.
Just use the default operation mode.
Kill off any instances of git, go and docker, just in case
Kill the server by connecting to it.
Last step: remove runtime libs from dependency_libs (they stay in deplibs)
Let the type of C char be signed to make the bare syscall API consistent between platforms.
Let's try to salvage the situation: Compile a separate program for each library.
Libraries that this one depends upon.
Like Linux, but with the current version available in verstring for coding it into the library header
Line breaks are important
Link against this library
Link the convenience library
Link the dlpreopened libraries before other libraries
Link the executable and exit
List of bundles to create when no argument is passed
Load all of your custom configurations from custom/
Lock this critical section if it is needed We use this script file to make the link, it avoids creating a new file
Loop over the list of objects to be linked.
Loop through the commands generated above and execute them.
Lots of our logic relies on knowing the shape of the token table.
METEOR_TOOL_PATH is the path to the 'meteor' that we will use for our tests.
Make a backup of the uninstalled library when relinking
Make a local copy of the built binary and ensure that is first in our path
Make a new Linenoise source directory
Make a new name for the extract_expsyms_cmds to use
Make another virtualenv to install into
Make executables depend on our current version.
Make it easier to run only the compaction test.
Make sure IFS has a sensible default
Make sure Linux mkdir for -p
Make sure dlfiles contains only unique files that won't be dlpreopened
Make sure dlprefiles contains only unique files
Make sure echo works.
Make sure lib_search_path contains only unique directories.
Make sure that fillrandom uses the same compaction options as compact.
Make sure that we'll have unique names for all the files so that data won't be overwritten.
Make sure the appname was passed in and is valid
Make sure the rpath contains only unique directories.
Make sure the server root folder was passed in and is valid
Make sure the variables and directories we expect to exist actually do.
Make sure the xrpath contains only unique directories.
Make sure under any mode, we can read user input.
Make sure we are in repo
Make sure we don't pick an alternate name that also overlaps.
Make sure we have at least an empty file.
Make sure we match foo.pyo and foo.pyc along with foo.py (but only once each)
Make sure we only generate libraries of the form `libNAME.la'.
Make the bucket accessible through website endpoints.
Makes it easier to see what header dependencies are missing
Many Bourne shells cannot handle close brackets correctly in scan sets, so we specify it separately.
Many Pathname operations use getwd when they shouldn't, and then throw odd exceptions.
May have to adjust if other operating systems use different directories.
Maybe even breaks it.
Maybe install the static library, too.
Maybe just do a dry run.
Maybe we'll need to selectively blacklist modules so that we can work on this a piece at a time.
Mksyscall reads those comments to generate the stubs.
Move out of source directory to avoid finding local numpy
My, what an old awk you have, Mr.
NKEYS         - number of key/value pairs to load BG_MBWRITEPERSEC - write rate limit in MB/second for tests in which there is one thread doing writes and stats are reported for read threads.
NO color option unless in PROMPT_COMMAND mode
NOTE: '--64' option breaks the compilation, even it is on by default on x64 mac: https://jira.mongodb.org/browse/SERVER-5575
NOTE: Changing this file will not affect anything until you rerun configure.
NSECONDS      - number of seconds for which to run each test in steps 2, 3 and 4.
Name of the PIC object.
Name of the non-PIC object.
Names of this library.
Need to hardcode shared library paths or/and link against static libraries
Needs to be the same as HEAD.
No PIC object so indicate it doesn't exist in the libtool object file.
No need for Glib integration
No need for STL compatibility Irrelevant Qt features
No such image, so make it
Node sets stdin to non-blocking, which causes Emacs shell to die after it exits.
Normally this is a single character, but if v1 and v2 contain digits, compare them as integers and fractions as strverscmp does.
Normally, after publishing a new Meteor release from checkout, you need to ssh to a machine running every supported platform and publish a build from it.
Not a directory, so check to see that there is only one file specified.
Note that this function assumes that the benchmark executes long enough so that "Compaction Stats" is written to stdout at least once.
Note that this will be ignored under Cygwin by default, as Windows ACLs take precedence over umasks except for filesystems mounted with option "noacl".
Note the libdir as a future libdir.
Note this may fail if jq is not installed.
Notes on test sequence: step 1) Setup database via sequential fill followed by overwrite to fragment it.
Now add the directory to shlibpath_var.
Now compile the dynamic symbol file.
Now create the libtool archive.
Now create the wrapper script.
Now hardcode the library paths
Now look for all potential identifiers in the source files.
Now prepare to actually exec the command.
Now set the variables for building old libraries.
Now, install the npm modules which are the dependencies of the command-line tool.
Nullify the symbol file.
NumPy may not distinguish between 64 and 32 bit ATLAS in the configuration stage.
ORIG_BUILDFLAGS is necessary for the cross target which cannot always build with options like -race.
Objects from convenience libraries.
Obviously it's not best practice to ever run as local system...
On Cygwin there's no "real" PIC flag so we must build both object types
On Rhapsody replace the C library is the System framework
On all known operating systems, these are identical.
On the production build servers, set data and stat files/directories not in /tmp or else the tempdir cleaning scripts will make you very unhappy.
Once you have set GIT_PS1_SHOWUPSTREAM, you can override it on a per-repository basis by setting the bash.showUpstream config variable.
One way to analyze the results is to run "grep real" on the resulting log files.
Only actually do things if our run command is non-null.
Only an error if not doing a dry-run.
Only append if the libtool object file exists.
Only attempt this if the compiler in the base compile command doesn't match the default compiler.
Only build a PIC object if we are building libtool libraries.
Only build a position-dependent object if we build old libraries.
Only check for convenience libraries
Only create the output if not a dry run.
Only do commands if we really have different PIC objects.
Only enable exit-on-error after the non-critical colorization stuff, which may fail on systems lacking tput or terminfo
Only execute mode is allowed to have -dlopen flags.
Only for *whilewriting, *whilemerging
Only for tests that do range scans
Only reason for doing that is that it mirrors the actual release process for docker.exe which is cross-built.
Only set LANG and LC_ALL to C if already set.
Only try to `git fetch` when the upstream branch is at a different SHA (so the API does not return 304: unmodified).
Optionally, you can supply a third argument with a printf format string to finetune the output of the branch status
Otherwise, compare as strings.
Otherwise, fall back to Homebrew's analytics.
Otherwise, just check it out.
Otherwise, use the dlname, so that lt_dlopen finds it.
Otherwise, we'll check format of the uncommitted code only.
Our patches allow us to link most of the libraries statically.
Output at end of script.
Overwrite existing tropohouse/warehouse.
POSIX demands no paths to be encoded in archives.
Parameter description:
Parse 'meta' options first to avoid the need to have them before other commands.
Parse our command line options once, thoroughly.
Parse the name list into a source file.
Parse the raw gcov report to more human readable form.
Parse the version information argument.
Pass these as arguments to this script.
Path to react-native folder inside node_modules
Perform a soft-purge of the surrogate key.
Porting Go to a new architecture/operating system combination requires some manual effort, though there are tools that automate much of the process.
Possibly a libtool archive, so verify it.
Possibly a libtool object, so verify it.
Prefer using a static library (so that no silly _DYNAMIC symbols are required to link).
Preload the old-style object.
Prepare the list of exported symbols
Prepend the subdirectory the object is found in.
Preserve any variables that may affect compiler behavior
Preserve exit status.
Prevent the cloned repository from having insecure permissions.
Print a usage message and exit.
Print all diags that occur in the .td files but not in the source.
Print commands before executing them (useful for troubleshooting)
Print info about current distro
Print info about upstream distro
Print out the colored progress info so that it can be brainlessly distinguished by users.
Probably can take from bash --version and check contains "x86_64" - Warn if the CI directory cannot be deleted afterwards.
Probably should distribute binaries built on these machines, but it should be OK for users to run.
Produces an ir-diffs.diff file that you can inspect for meaningful differences in JIT output.
Provide the docker version for debugging purposes.
Pull out the error names for later.
Pull out the signal names for later.
Qt requires the char16_t PCRE library, -lpcre16, which is not present on some Linux distributions, so don't force it.
Qt's configure's idea of "silent" is still quite noisy.
Quote arguments (to preserve shell metacharacters).
Quote the link command for shipping.
Quote the relink command for shipping.
RANGE_LIMIT   - the number of rows to read per range query for tests that do range queries.
REMOVE after next semver-major
REQUIRE: db_bench binary exists in the current directory
Read the .lo file If there is no directory component, then add one.
Read the bundle version from the meteor shell script.
Read the libtool library.
Reads etc/ld.so.conf and/or etc/ld.so.conf.d/*.conf and returns the appropriate linker flags.
Recognize several different file suffixes.
Redirect to a temporary location.
Reduce our support burden by showing a user-friendly error.
Relative path: add a thisdir entry.
Remember objdir for removal later, being careful to avoid duplicates
Remove /tools/setup_for_hacking.sh to get the root directory
Remove /tools/setup_server_smokes.sh to get the root directory
Remove a-package-named-bar so that the local accounts-ui package is the only thing that determines whether we need to set PACKAGE_DIRS.
Remove agetty and inittab config
Remove all images which don't have docker or ubuntu in the name
Remove all the ones other than our architecture.
Remove alpha variance in "#line" directives.
Remove esprima tests to reduce the size of the dev bundle
Remove existing "server-tests" symlink, if present
Remove existing symlink, if present
Remove our outputs, but don't remove object files since they may have been created when compiling PIC objects.
Remove the files from the repo
Remove this search path later
Remove unnecessary files
Remove version info from name if versioning should be avoided
Renaming some stuff in the cpp file
Replace all uninstalled libtool libraries with the installed ones
Replace the output file specification.
Requirements: - The current directory should be a checkout of the docker source code (https://github.com/docker/docker).
Restore saved environment variables
Restore the uninstalled library and exit
Restore the value of output.
Return a directory name, but don't create it in dry-run mode
Return to starting directory
Return value 0 means all regression tests pass.
Reveal what header dependencies are missing
Rhapsody C and math libraries are in the System framework
Rhapsody C library is in the System framework
Rig it so that a single connection will cause it to exit.
Run C program to print error and syscall strings.
Run a server on the same port as mongod, so that mongod fails to start up.
Run from react-native root
Run local precommit script if there is one
Run once to build all of the packages
Run setup for each distro accordingly
Run tests inside each of the versioned containers, copy cwd into npm's copy of node-gyp so it'll be invoked by npm when a compile is needed run_tests(version, test-commands)
Run the actual program with our arguments.
Run the integration tests
Run with as parameter a setup.py that works in the current directory e.g. no os.chdir() It will run twice, the first time will crash
Running those commands is not automatic.
Sadly it is an enum without introspection, so instead make it macros so we can control its shape on re-requires of the .hpp file
Same as above, but docker info
Sanity check to see if we're not breaking anything by replacing npm
Save for use by make.sh and scripts it invokes
Save the location of the current completion dump file.
Scour for shim files.
Script for removing specified release dir from code.angularjs.org.
Script for removing tags from the Angular bower repos
Script for updating code.angularjs.org repo from current local build.
Script for updating the Angular bower repos from current local build.
Script to initialize angular repo - install required node packages - install Karma - install git hooks
Search the libtool library
Sed substitution that helps us do robust quoting.
Sed to process GitHub Markdown 1-2 Remove comment code from metadata block
See contrib/mkimage-rinse.sh for a way to build CentOS images on other systems.
See contrib/mkimage-yum.sh for a way to build CentOS images on systems with yum installed.
See http://sam.zoy.org/wtfpl/COPYING for more details.
See https://github.com/docker/docker/pull/8845
See if our shared archives depend on static archives.
See if we need to build an old-fashioned archive.
See the names of the shared library.
See this helpful document on writing portable shell scripts: http://www.gnu.org/s/hello/manual/autoconf/Portable-Shell.html
See types_darwin.c and types_linux.c for examples.
See what "npm_config_*" things there are in the env, and make them permanent.
Seekrandomwhilewriting
Seriously, don't build any examples
Set ZSH_CACHE_DIR to the path where cache files should be created or else we will use the default cache/
Set ZSH_CUSTOM to the path where your custom config files and plugins exists, or else we will use the default custom/
Set d1 to be the next thing to compare from v1, and likewise for d2.
Set environment variables so that we can compile rocksdb using fbcode settings.
Set this to skip a set of tests which aren't critical for getting key metrics.
Set tunnel-id only on Travis, to make local testing easier.
Set up a command to remove the reloadable object files after they are used.
Set up the nodenv node version manager if present
Set up the ranlib parameters.
Sets the default graphics system to the raster engine
Setting up the proxy for remote repo access
Shift the -v to the end of the parameter list
Should already be sitting in the npm folder.
Since it's a grep and append that *might* actually be safe (whether the extra lines show up might not affect the output) but someone should look at this again.
Skip --install_dir and --fbcode_dir.
Skip directories that are in the system default run-time search path.
Skip this library if it cannot be dlopened.
So, we have pinned `virtualenv` to the last known working version to avoid this failure.
Some C libraries present alternate versions for binary compatibility and translate them on the way in and out of system calls, but there is almost always a #define that can get the real ones.
Some PHP constructs modify whole-process state or are not well-suited to be tested in a webserver.
Some change in virtualenv 14.0.5 caused `test_f2py` to fail.
Some compilers have problems with a `.al' extension so convenience libraries should have the same extension an archive normally would.
Some other compiler argument.
Some other compiler flag.
Some warnings are out of our control, so adjust the number as needed.
Sort the filelist so that directories appear before files.
Speed up build times by skipping the creation of the offline package for debug builds on the simulator since the packager is supposed to be running anyways.
Split v1 and v2 into their leading digit string components d1 and d2, and advance v1 and v2 past the leading digit strings.
Start in website/ even if run from root directory
Start the docker-in-docker daemon from the image we just built
Static build on Mac OS X only
Stick the inst_prefix_dir data into the link command.
Strip any trailing slash from the destination.
Strip out hex symbols and other extraneous differences
Substitute the hardcoded libdirs into the rpath.
Suppress compiler output if we already did a PIC compilation.
Switch back when this issue with xctool has been resolved.
TODO create redirect from builds/*/i686 to builds/*/i386
TODO figure out why "-C -" doesn't work here "curl: (33) HTTP server doesn't seem to support byte ranges.
TODO hackpatch for no -C support :'(
TODO to make (even) more resilient: - Wait for daemon to be running before executing docker commands - Check if jq is installed - Make sure bash is v4.3 or later.
TODO(kailiu) following work is not complete since we still need to figure out how to add the modified files done pre-commit hook to git's commit index.
TODO: We use xcodebuild because xctool would stall when collecting info about the tests before running them.
TODO: list more e.g. shell completion things here perhaps using a single script as a shell-completion entry point.
TODO: we also need to get the files of the latest commits.
Tags a release so that travis can do the actual release.
Tell the user how we did.
Test 11: random read while writing
Test 12: range scan while writing
Test 13: reverse range scan while writing
Test 16: random read while merging
Test 17: range scan while merging
Test 18: reverse range scan while merging
Test 2a: sequential fill with large values to get peak ingest adjust NUM_KEYS given the use of larger values
Test 2b: sequential fill with the configured value size
Test 2c: same as 2a, but with WAL being enabled.
Test 2d: same as 2b, but with WAL being enabled.
Test 3: single-threaded overwrite
Test 5: random range scans
Test 6: random reverse range scans
Test again, we may have decided not to build it any more
Test that we do not access private attributes of other objects.
That's a bit of a heavy lift.
That's faster, and goma relies on having matching binary hashes on client and server too.
That's probably worth checking to make sure, just in case.
The 'exit 0' below will be executed if any preceding command fails.
The Bash shell script executes a command with a time-out.
The Dockerfile, make.sh and release.sh should all be from the same source code revision.
The PATH hackery in wrapper scripts is required on Windows and Darwin in order for the loader to find any dlls it needs.
The TAGs below are defined such that we never get into a situation in which we disable both kinds of libraries.
The TXT record for backends.angularjs.org is a CSV of the IP addresses for the currently serving Compute Engine backends.
The Windows (MSYS) Git is not compatible with normal use on cygwin
The `-D` flag consumes recognized options so that the actual command parsing won't be affected.
The arguments are parts of a PS1 string.
The auto-generated files have names beginning with z.
The colors are based on the colored output of "git status -sb" and are available only when using __git_ps1 for PROMPT_COMMAND or precmd.
The command line is too long to execute in one step.
The command line is too long to link in one step, link piecewise.
The compiler in the base compile command matches the one in the tagged configuration.
The constant "fillseq" which we pass to db_bench is the benchmark name.
The correct way to call this script is inside a container built by the official Dockerfile at the root of the Docker source code.
The current "srcfile" will either be retained or
The effects of -static are defined in a previous loop.
The environment variables are also optional.
The first argument is the command name.
The first file doesn't have a previous command to add.
The following is split over four lines so Phabricator doesn't think this file is generated
The gcc command line prints all the #defines it encounters while processing the input
The generator is "mkerrors.sh".
The library was specified with -dlpreopen.
The linker will fail if global_symbol_pipe really was required.
The list of threads is optional and when not set is equivalent to "24".
The main benefit behind disabling WAL is to make loading faster.
The name of the static archive.
The name of this program:
The name that we can dlopen(3).
The native IRIX linker understands -LANG:*, -LIST:* and -LNO:* so, if we see these flags be careful not to treat them like -L
The normal case, without worrying about digits.
The only shell it won't ever work on is cmd.exe.
The optional third parameter will be used as printf format string to further customize the output of the git-status string.
The ordering is very important and should not be changed.
The presence of these empty directories is sufficient to convince Cocoa that the application supports the named localization, even if an InfoPlist.strings file is not provided.
The previous "srcfile" becomes the current argument.
The problem exists in FreeBSD 2.2.6 and is fixed in FreeBSD 3.1.
The program doesn't exist.
The prompt status always includes the current branch name.
The real first argument should be the name of the installation program.
The repository status will be displayed only if you are currently in a git repository.
The s3cmd guessed mime type for text files is often wrong.
The statement above tries to avoid entering an endless loop below, in case of cyclic links.
The syscall package provides access to the raw system call interface of the underlying operating system.
The tests in step 1 are only run for 1 thread.
The two components differ in length, and the common prefix contains only leading zeros.
The variables are: NKEYS         - number of key/value pairs to load NWRITESPERSEC - the writes/second rate limit for the *whilewriting* tests.
The windows integration tests are run against this inner daemon.
Then .hhas files are included en-masse.
Then start docker in daemon mode:
Then we can check whether they linked in statically or dynamically with ldd.
There are currently 15 tests in those steps and they are repeated for each entry in list-of-threads so this variable lets you control the total duration to finish the benchmark.
There are really only two kinds -- those that use the current revision as the major version and those that subtract age and use age as a minor version.
There are some bash-isms, because maintaining *two* fully-portable posix/bourne sh scripts is too much for one project with a sane maintainer.
There are three entry points:
There is a vestigal capability to default to running the 'meteor' that sets next to this script in a checkout, but we should probably just take that out.
There may be an optional sh(1) argument at the beginning of install_prog (especially on Windows NT).
These are relics of 0.2 npm installs.
These modes are in order of execution frequency so that they run quickly.
These must come last.
These systems don't actually have a C library (as such)
These systems don't actually have a C or math library (as such)
This SHOULD never happen, but just in case, also blow away any containers that might be around.
This allows tests from steps 2, 3, 4 to be repeated faster.
This assumes single-version convenience libraries.
This avoids duplicate filename problems on some systems.
This awful perl line means "print everything after the last whitespace".
This bloats our dev bundle.
This code stresses the "libraries are programs" paradigm to its limits.
This configuration line is taken from Homebrew formula: https://github.com/mxcl/homebrew/blob/master/Library/Formula/openssl.rb
This doesn't have to be quite as cross-platform as install.sh.
This environment variable determines our operation mode.
This fallback is for the cmake build, which won't have an FBCODE_DIR environment variable, and runs this from the runtime subdir.
This file becomes the install section of the generated spec file.
This file lists all individuals having contributed content to the repository.
This function resides in the "lib/compfix.zsh" script sourced above.
This hand-written Go file implements system calls that need special handling and lists "//sys" comments giving prototypes for ones that can be auto-generated.
This hand-written assembly file implements system call dispatch.
This ignores the stuff in node_modules/.bin, but that's OK.
This is a convenience script for reporting issues that include a base template of information.
This is a shared library Warn about portability, can't link against -module's on some systems (darwin)
This is a terrible hack.
This is a whole lot faster than calling JSDoc recursively.
This is also unnecessary, but it's not possible to turn it off.
This is an annoying source of bugs.
This is i386 even on x86_64 machines
This is incremented when pushing a new build of Clang at the same revision.
This is necessary because there is no way to change the working directory in hhvm before we exec (chdir only changes a var in the execution context).
This is particularly important on AIX, because we don't support having both static and shared libraries enabled at the same time on that platform, so we default to a shared-only configuration.
This is problematic for some assets, so force their mime types to be correct.
This is the default directory for Ubuntu installations (if installed with the *.deb).
This is the default set of browsers to use on the CI server unless overridden via env variable
This is the magic to use -rpath.
This is the part we're really interested in.
This is to avoid mixing bundles from different versions of the code.
This is used for the "readwhile" tests.
This is valid on all known static and shared platforms.
This is what dist.py normally does.
This library was specified with -dlopen.
This library was specified with -dlpreopen.
This machine-generated file defines the system's error numbers, error strings, and signal numbers.
This makes running a Bash script behave more like a Ruby script and avoids hard-to-debug issues if the Bash script is updated at the same time as being run.
This may have to be revisited, in case too many convenience libraries get linked in and end up exceeding the spec.
This might be a little naive.
This must be done before running compinit.
This prevents here-documents from being left over by shells.
This runs with a vector memtable and the WAL disabled to load faster.
This runs with a vector memtable.
This script allows you to see repository status in your prompt.
This script automates ssh'ing into machines and running the publish command.
This script builds various binary artifacts from a checkout of the docker source code.
This script creates the Resources directory for the bundle being built by the Xcode target that calls it if the directory does not yet exist.
This script generates Java structures that contain the offsets of fields in various ELF ABI structures.
This script generates certificates that can be used to test SSL client authentication.
This script is documentation more than anything else.
This script is intended to create empty locale directories (.lproj) in a Cocoa .app bundle.
This script is supposed to be invoked as part of Xcode build process and relies on environment variables (including PWD) set by Xcode
This script is useful on systems with rinse available (e.g., building a CentOS image on Debian).
This script is useful on systems with yum installed (e.g., building a CentOS image on CentOS).
This script looks for bundles built by make.sh, and releases them on a public S3 bucket.
This script produces a list of all diagnostics that are defined but not used in sources.
This script runs or (given -n) prints suggested commands to generate z files for the current system.
This script serves as an example to demonstrate how to generate the gRPC-Go interface and the related messages from .proto file.
This script should be run from the base of "nuclide-debugger-node".
This script will check out llvm and clang into third_party/llvm and build it.
This script wraps the `Atom` binary, allowing the `chromedriver` server to execute it with positional arguments and environment variables.
This scripts automates the release process of Meteor Tool.
This shell script fills the gap.
This should be run from the parent of the tools directory.
This should be used with the LevelDB fork listed here to use additional test options.
This uses the latest available iOS SDK, which is recommended.
This variable tells wrapper scripts just to set shlibpath_var rather than running their programs.
This variable tells wrapper scripts just to set variables rather than running their programs.
This way, build works before we generate the right things.
This will make the sha appear to change constantly, but without any insight into file state, it's the safest fallback
This wrapper script should never be moved out of the build directory.
Tidy up any temporary files from the CI run
Tiny little helper to create the empty php7 versions of your regression tests.
To always force a new build if someone interrupts their build half way.
To install, run the following command as root:
To run it, set METEOR_TOOL_PATH to the 'meteor' script to use, plus, as usual, METEOR_WAREHOUSE_DIR if you want to stub out the warehouse.
To see the mongo changelog, go to http://www.mongodb.org/downloads, click 'changelog' under the current version, then 'release notes' in the upper right.
To select a specific SDK, run 'xcodebuild -showsdks' to see the available SDKs and replace iphoneos with one of them.
To test run "brew update --simulate-from-current-branch"
Trace commands as they're executed.
Transform .lo files to .o files.
Transform all the library objects into standard objects.
Transform arg to wrapped name.
Transform deplibs into only deplibs that can be linked in shared.
Transform the symbol file into the correct name.
Travis legacy boxes give you 1.5 CPUs, container-based boxes give you 2 CPUs
Try creating the bucket.
Try looking first in the location we're being installed to.
Try sorting and uniquifying the output.
Try to find a suitable make If the MAKE environment var is set, use that.
Try to get the absolute directory name.
Tune values for level and universal compaction.
Turn off GStreamer support
Typecheck, compile with the emitter and run the generated assembly
Uncomment to make CI fail once all nodes are updated.
Unknown arguments in both finalize_command and compile_command need to be aesthetically quoted because they are evaled later.
Unless otherwise specified, we'll not generate html report by default
Unlock the critical section if it was locked
Unnecessary Qt features
Unnecessary Qt modules
Unnecessary Unix-specific features
Unshift command back into argument list (unless argument list was empty).
Update dependencies.sh file with the latest avaliable versions
Update these values after building the dev-bundle-mongo Jenkins project.
Update these values after building the dev-bundle-node Jenkins project.
Upload binaries and tgz files to S3
Upload the files to S3 - we disable mime-type detection by the python library and just guess from the file extension because it is surprisingly more accurate, especially for CSS and javascript.
Upload the index script
Upon time-out expiration SIGTERM (15) is sent to the process.
Usage: First do 'make -C ../src test' to generate the .out files.
Usage: scripts/admin/copy-bootstrap-tarballs-from-jenkins.sh BUILDNUMBER where BUILDNUMBER is the small integer Jenkins build number.
Usage: scripts/admin/copy-windows-installer-from-jenkins.sh BUILDNUMBER where BUILDNUMBER is the small integer Jenkins build number.
Use '-' rather than '.', since we only want one extension on DOS 8.3 filesystems.
Use ComputerName if possible.
Use a potentially-scary awk script to split the single hphp.y parser into two outputs.
Use a single thread to reduce the variability in the benchmark.
Use colors, but only if connected to a terminal, and that terminal supports them.
Use mostly bundled libraries for Darwin.
Use only awk features that work with 7th edition Unix awk (1978).
Use standard objects if they are pic
Use the bundled libraries, vs system-installed
Use these flags when compiling the tests and final binary
Used for testing purposes, e.g., for testing formula migration after renaming it in the currently checked-out branch.
Used to delete bulky subtrees.
Users may have these set, pointing the system Ruby at non-system gem paths
Usually no arguments are needed, but mkerrors.sh will pass its arguments on to godefs.
VAL_SIZE      - the length of the value in the key/value pairs loaded.
Verify that the sample dump file is undumpable and then redumpable.
Verify we can get the remote node to respond to _ping
WAL can be either disabled or enabled depending on the input parameter (1 for disabled, 0 for enabled).
Wait for Connect to be ready before exiting Time out if we wait for more than 2 minutes, so that we can print logs.
Warm the cache with recursive wget.
Warn if it was a shared library.
We also need to preload any dependent libraries so libltdl's deplib preloader doesn't bomb out in the load deplibs phase.
We also redirect TEMP to not use the environment TEMP as when running as a standard user (not local system), it otherwise exposes a bug in posix tar which will cause CI to fail from Windows to Linux.
We also tag the uploaded files with the proper Surrogate-Key, which we will later purge in our API call to Fastly.
We cannot seem to hardcode it, guess we'll fake it.
We change directories to make sure that python won't find the copy of numpy in the source directory.
We compile a program, linking it against the deplibs as a proxy for the library.
We don't need to create a wrapper script.
We don't strip on Mac because we don't know a safe command.
We don't want to rely on the grammar to have a fixed start and end token, so lets parse the file and make two macros for the min and max
We handle these cases below.
We have no uninstalled library dependencies, so finalize right now.
We havent found an Atom.app, use spotlight to search for Atom
We just download the bootstrap script by default and execute that.
We keep going just in case the user didn't refer to lt_preloaded_symbols.
We might want to check whether the library exists or not.
We must manually print logs here because travis will not run after_script commands if the failure occurs before the script phase.
We need a known version of the kernel-uek-devel headers to set CGO_CPPFLAGS, so grab the UEKR4 GA version This requires using yum-config-manager from yum-utils to enable the UEKR4 yum repo
We need an absolute path.
We need to accept at least all the BSD install flags.
We need to change the working directory because php5 xdebug only accepts filenames relative the working directory and so line breakpoint tests would fail if not run from the root test directory.
We need to display help for each of the modes.
We need to hardcode the library path
We need to know -static, to get the right output filenames.
We need to manually fork and exec (as opposed to using proc_open) because we have to close the listening socket before we exec.
We need to set the CGO_CPPFLAGS environment to use the updated UEKR4 headers with all the userns stuff.
We only need to search for static libraries
We prevent these files from being run in server mode by creating .noserver files if they contain one of the bad symbols.
We save a shrinkwrap file with it, too.
We save the old values to restore during execute mode.
We should really fail if result is no 1.
We should set the runpath_var.
We should set the shlibpath_var
We still want the files in our tree since they are checked in
We use Meteor fork since we added some changes to the building script.
We used to do the same as -all-static on platforms that didn't have a PIC flag, but the assumption that the effects would be equivalent was wrong.
We want this to fail if the bundles already exist and cannot be removed.
We want to build a binary that includes SSL support but does not depend on a particular version of openssl on the host system.
We're trying link a shared library against a static one but the system doesn't support it.
Were list-of-threads specified as "1 2 4" then the tests in steps 2, 3 and 4 above would be repeated for 1, 2 and 4 threads.
Whatever version is checked out will be built.
Whenever we create different ones for PIC/non-PIC, this we'll have to duplicate the extraction.
Whether the deplib will be linked statically
Will build using it and check DBs generated by all previous tags can be opened by it.
Will suggest user to add this script to pre-commit hook if their pre-commit is empty.
Windows and symlinks don't get along well
Without this assignment, base_compile gets emptied.
Work around backward compatibility issue on IRIX 6.5.
Work around this by setting stdin to blocking again.
Write go tool cgo -godefs input.
Write the output to both stdout and report file.
X11-less with QPA (aka Lighthouse)
XXX For some reason, make is building all the docs every time.
XXX there is no os.windows.x86_64 as we don't build for it at the moment
Xcode project file for React Native apps is located in ios/ subfolder
You can also see if currently something is stashed, by setting GIT_PS1_SHOWSTASHSTATE to a nonempty value.
You can configure this per-repository with the bash.showDirtyState variable, which defaults to true once GIT_PS1_SHOWDIRTYSTATE is enabled.
You can configure this per-repository with the bash.showUntrackedFiles variable, which defaults to true once GIT_PS1_SHOWUNTRACKEDFILES is enabled.
You can further control behaviour by setting GIT_PS1_SHOWUPSTREAM to a space-separated list of values:
You can use this script if you want to use an external cdb lib.
You can use this to select certain tests to run, eg.
You will need to install `pulls` and `issues` from https://github.com/crosbymichael/pulls
Zsh Theme Chooser by fox (fox91 at anche dot no) This program is free software.
__git_ps1 accepts 0 or 1 arguments (i.e., format string) when called from PS1 using command substitution in this mode it prints text to add to bash PS1 prompt (includes branch name)
__git_ps1 requires 2 or 3 arguments when called from PROMPT_COMMAND (pc) in that case it _sets_ PS1.
_build generates fast-path.go and gen-helper.go.
_init reads the arguments and sets up the flags
_needgen is a helper function to tell if we need to generate files for msgp, codecgen.
`chromedriver` only allows 'switches' to be specified when starting a browser, not positional arguments, so this script accepts the following special switches:
a helper to provide ".exe" when it's appropriate
a race to see which make process will be the one to install marked
a race to see which make process will be the one to install marked-man
add -backports, like our users have to
add contrib and non-free
add prefix library if passed official image
add the universe, updates, and security repositories
add the updates and security repositories
add the updates repository
add this line back to normal code path when https://jira.mongodb.org/browse/SERVER-19123 is resolved
allow networking init scripts inside the container to work without extra steps
allow replacing httpredir mirror
also remove any symlinks to this file.
always keep a non-empty value in "srcfile"
amazon linux yum will fail without vars set
and its dependency_libs
and remove the translations, too
arg 1 is the working directory to cd to arg 2 is the hhvm binary arg 3 is "-c" arg 4 is the ini file arg 5 is the test to run
arg Now actually substitute the argument into the commands.
arg is usually of the form 'gcc ...'
argument parsing loop
as the Linux box isn't responding for some reason.
assume a copy of this script is in builddir
assume pwd is builddir
aufs in aufs is faster than vfs in aufs
autoconf 2.59 or newer
avoid clobbering other PROMPT_COMMANDs.
aws s3 ls returns 0 when it lists nothing
bash v4 on Windows CI requires CRLF separator
bits of this were adapted from lxc-checkconfig see also https://github.com/lxc/lxc/blob/lxc-1.0.2/src/lxc/lxc-checkconfig.in
bomb out if it didn't work
borrows from https://github.com/rvagg/dnt/ Simple setup function for a container: setup_container(image id, base image, commands to run to set up)
build the daemon image
but shell scripts are "executable" too...
calculate the name of the file, without its directory
cdb-0.75 lacks support for installing header files and creating a  library which programs can link against.
change default debootstrap variant"
change default package includes"
check if config file exists
check if config file is writeable
check if no arguments were given, and that version is not set
check to see which repo they are trying to install from
check whether printf supports -v
check whether stderr is a tty.
checkout the SHA1 we want to publish
cmd/cgo doesn't support llvm-gcc-4.2, so we have to use clang.
code.angularjs.org is served out of port 8003 on these backends.
com.facebook.soloader.MinElf uses these structures while parsing ELF files.
commented out since we aren't uploading binaries right now.
compiling the symbol table file with pic_flag works around a FreeBSD bug that causes programs to crash when -lm is linked before any other PIC object.
completions will always start with /
convert absolute version numbers to libtool ages this retains compatibility with .la files and attempts to make the code below a bit more comprehensible
copy batch script to windows machine, in a funky way, by splicing each line of publish-meteor-tool.bat into a Windows `echo` command, with no escaping.
copy the files from the build
copy the meteor session file to the remote host
could be an import, or static
create the tarball file so it has the right permissions (ie, not root)
default branch name for checkouts with no layout:
default upstream is SVN if available, else git
define lt_preloaded_symbols some_other_symbol
delete existing batch script if it exists
deplib doesn't seem to be a libtool library
dir for building tar in
disable binary uploads for now.
diverged from upstream
do not add paths which are already there
do nothing can't run `exit`, as this would exit the executing shell
do our best to avoid clobbering the datafile in a race condition
docker-dev or #docker-maintainers"
docker-maintainers on IRC to get this CI server updated."
doesn't use systemd, doesn't have a devel package for it
don't mistake common scripts like .febootstrap-minimize as image-creators
don't publish every build to npm
don't track excluded directory trees
download dev bundle if we don't have it already
dummy test just to compact the data
echo "Backing up old generated files"
echo "Follow Microsoft Visual C++ 2008 Redistributable Package setup on screen" bash winetricks vcrun2008
echo "Installing without make.
echo "Running prebuild"
endif if defined (S_IXGRP)
endif ifdef __cplusplus
ensure GIT_CONFIG is unset as we need to operate on .git/config
ensure OS ABI compatibility
ensure that the pip / setuptools versions deployed inside the venv are recent enough
ensure we don't munge line endings on checkout
exit if any command fails
export path again with our temporary npm3 directory first, so we can use npm 3 during builds
export path so we use our new node for later builds
export path so we use the downloaded node and npm
fast_install is set to needless
faster operation with preloaded eatmydata
fbconfig passes a couple --foo arguments.
figure out the soname
fill up the db for readrandom benchmark (1GB total size)
fill up the db for readrandom benchmark with filluniquerandom (1GB total size)
finally, DESTROY ALL THINGS
find the common root of a list of matches, if it exists
fixup the dll searchpath if we need to.
fluent-logger-golang deps
for "btrfs/ioctl.h" (and "version.h" if possible)
for "git commit" info in "docker -v"
for "sd-journal.h" and libraries
for MKS sh The HP-UX ksh and POSIX shell print the target directory to stdout if CDPATH is set.
for apparmor debhelper
for apparmor_parser for testing the profile
for bash-completion debhelper integration
for detecting things like libsystemd-journal dynamically
for easy ".deb" building
for systemd debhelper integration
for the pkg-config command
forked golang.org/x/net package includes a patch for lazy loading trace templates
func_extract_an_archive dir oldlib
func_extract_archives gentop oldlib ...
func_infer_tag arg Infer tagged configuration to use if any are available and if one wasn't chosen via the "--tag" command line option.
func_win32_libid arg return the library type of file 'arg'
gelf logging driver deps
get "Development Tools" packages and dependencies we also need yum-utils for yum-config-manager to pull the latest repo file
get "Development Tools" packages dependencies
get desired notary commit, might also need to be updated in Dockerfile
get graph and distribution packages
get hash files too (see hash_files() in hack/make.sh)
get into this script's directory
get keys from "meteor admin get-machine" command inputs: SESSION_FILE, METEOR, PLATFORM, CHECKOUT_DIR outputs: USERNAME, HOST, PORT, TEMP_KEY, TEMP_PRIV_KEY
get libnetwork packages
get list of available X windows.
get rpm-build and curl packages and dependencies
get some config options from git-config
get the ip, inner and outer ports.
get the npm dist-tag from a custom property (distTag) in package.json
get the upstream from the "git-svn-id: ..." in a commit message (git-svn uses essentially the same procedure internally)
git add --all git commit -m "update website" git push cd ../relay/website
git clean -dfx git fetch git rebase
give us a command-not-found later
given as parameter to double check.
hacky workarounds for Bash 3 support (no associative arrays)
hax to create a local empty array
highlight Error with underline and red color
https://github.com/mdcallag/leveldb-1 http://smalldatum.blogspot.com/2015/04/comparing-leveldb-and-rocksdb-take-2.html
if defined (HAVE_DOS_BASED_FILE_SYSTEM)
if not, create config file
if our current go install has -cover, we want to use it :)
if our generated image has a decent shell, let's set a default command
if root is "/", we want it to become ""
if the lib is a module then we can not link against it, someone is ignoring the new warnings I added
if there's an argument we look up the value
if we didn't specify a tag and we're going to delete our dir, let's just build an untagged image so that we did _something_
if we hit enter on a completion just go there
ifdef FREEBSD_WORKAROUND
initctl (for some pesky upstart scripts)
inner port is like outer port with last two digits inverted.
install all required packages for rocksdb
install all required packages for rocksdb that are available through yum
install apparmor utils if they're missing and apparmor is enabled in the kernel otherwise Docker will fail to start
install experimental packages from OBS://Virtualization:containers
install gcc/g++ 4.8.2 via CERN (http://linux.web.cern.ch/linux/devtoolset/)
install mode needs the following variable:
install needed packages
install npm 3 in a temporary directory
intentionally undocumented for now
it may work, but I only see pain this route and don't want to support it
just create a tarball, especially for dockerbrew (uses repo as tarball name)"
just double-checking :)
kill all of subprocess on interrupt
kill meteor, see mongo is still running
ld.so.conf may include relative include paths.
ldconfig sudo rm -rf sbin/ldconfig
libcontainer deps (see src/github.com/opencontainers/runc/Godeps/Godeps.json)
libraries that don't have pic variant will not be included
libtool clean and uninstall mode
list or return the desired directory
location of bzip headers and libraries
location of gflags headers and libraries
location of libunwind
location of snappy headers and libraries
location of zlib headers and libraries
logrus is a common dependency among multiple deps
look for old 0.x cruft, and get rid of it.
maintain the data file
maintains a jump-list of the directories you actually use
make some warnings fatal, mostly to match windows compilers
make sure /etc/resolv.conf has something useful in it
make sure our packages lists are as up to date as we can get them
make sure that node exists
make sure the library variables are pointing to the new library
make sure we fail if the test failed
make sure we have an absolute path to our final tarball so we can still reference it properly after we change directory
make the tar for node's deps
make the zip for windows users
measure fillseq + fill up the DB for overwrite benchmark
measure fillseq with bunch of column families
measure memtable performance -- none of the data gets flushed to disk
measure overwrite performance
measure overwrite performance with bunch of column families
measure readrandom after load with filluniquerandom with 6GB block cache
measure readrandom with 100MB block cache
measure readrandom with 6GB block cache
measure readrandom with 6GB block cache and tailing iterator
measure readrandom with 8k data in memtable
measure readwhilewriting after load with filluniquerandom with 6GB block cache
move library search paths that coincide with paths to not yet installed libraries to the beginning of the library search list
move the files from the build
much faster package installation
need to echo "" after, because Posix sed doesn't treat EOF as an implied end of line.
need to make sure these kills take effect
need to switch lsb_dist to match yum repo URL
no user namespace support enabled
non-PIC code in shared libraries is not supported
normalize the working dir to the directory of the script
not sure why we need both, but it seems to help clean up rogue mongo and phantomjs processes.
not-installed libtool libraries
note that this will also skip adding universe and/or security/updates to sources.list"
note that we can only use strict sh-compatible patterns here.
note: grep -r is not portable.
now actually clean, but only if there's anything TO clean
now prefix is where npm would be rooted by default go hunting.
now remove the package modules, and the .npm folder itself.
now, let's go destroy individual btrfs subvolumes, if any exist
npm command completion script
older versions of dev-tools do not have tar
only count directories
only replace the *last* dash: yes, tap filenames suck
only static version available
only then publish to github
open the Jasmine SpecRunner
otherwise, try to find gmake, and then make.
override exit code in case wd_remove did not remove any points TODO: we should handle this kind of logic better
packages to ignore for space savings
packaging for "sd-journal.h" and libraries varies
parse configuration values
parse rest of options
paths that contain not-installed libtool libraries
perform some very rudimentary platform detection
place dlname in correct position for cygwin
platform is not provided, use latest gcc
populate directory list, avoid clobbering any other precmds.
populate directory list.
precise has a few package issues - dh-systemd doesn't exist at all
prefer case sensitive
prepare die.js so that we have a server that loads packages and dies
prevent CircleCI from killing the process for inactivity
prevent creating another X frame if there is at least one present.
prevent init scripts from running during install/update policy-rc.d (for most scripts)
print a value from a JSON file by key
print build tags in alphabetical order
print totals of all processes (outer, mongo, inner)
produce equivalent output to --count for older versions of git
publish to npm and update dist tags
pull a couple packages from backports explicitly (build failures otherwise)
pulled from https://gist.github.com/cdown/1163649
push the tag deletion to github
push the tag to github
push to csp branch on github
put the numpy repo in the chroot directory
relate frequency and time
relink executable if necessary
remove .exe since cygwin /usr/bin/install will append another one anyway
remove all the sub directories
remove any links into the .npm dir, or links to version-named shims/symlinks.
remove die.js, we're done with package tests.
remove our temporary npm3 directory
remove the include guard's #endif (-e doesn't work for this)
remove the legacy UUID file if detected.
rename Taps directories this procedure will be removed in the future if it seems unnecessary
report.txt provides a high level statistics
report.txt provides a high level statistics This should be run from the parent of the tools directory.
required for bind-mounting /dev/mqueue into containers
required for containerd and runc clone
rinse fails a little at setting up /dev, so we'll just wipe it out and create our own
rm -f *_generated_test.go
run again in chroot with this time testing
run different jobs based on CicleCI parallel container index
run tests and check output
running on devbox, just print out the values
same for security updates
save host key and login private key to temp files
script for creating a zip and tarball for inclusion in node
script from http://stackoverflow.com/questions/12133583
see also ".mailmap" for how email addresses and names are deduplicated
see also rudimentary platform detection in hack/install.sh
see https://en.wikipedia.org/wiki/ANSI_escape_code#Colors
see symlink-check above in file_magic test
set java home so we can build rocksdb jars
set up repos in the chroot directory for installing packages
should download the headers file
skip empty lines and comments
skip files that aren't of the format xxxx.N.md (like README.md)
skip version detection and tagging (ie, precise also tagged as 12.04)"
some older macos returns i386 but can run 64 bit binaries.
some rudimentary detection for whether we need to "sudo" our docker calls
someday, we might potentially support multiple GOARM values, in which case we might get armhf here too
source rather than executing directly to ensure the entire file is read into memory before it is run.
source this file in your shell to get a POSIX locale (which will break many programs, but that's kind of the point)
start a bunch of phantomjs processes
start the benchmark app
stick to the default debootstrap mirror if one is not provided
strict debootstrap (do not apply any docker-specific tweaks)"
switch based on node version.
synchronously get the dev bundle and NPM modules if they're not there.
sysroot_ld_path.sh /abspath/to/sysroot
tag specific SteamOS version number, if available (1.0, 2.0, etc.)
tag specific Tanglu version number, if available (1.0, 2.0, etc.)
tag specific Ubuntu version number, if available (12.04, etc.)
tag the specific debian release version (which is only reasonable to tag on debian stable)
tags the current commit as a release and publishes all artifacts to the different repositories.
test for cygwin because mv fails w/o .exe extensions
test whether "btrfs/version.h" exists and apply btrfs_noversion appropriately
test whether "libdevmapper.h" is new enough to support deferred remove functionality.
the Makefile will do a "docker build -t docker ." and then "docker run hack/make.sh" in the resulting image.
the above command should be used before it gets too long
the codename of the release
the command line is too long to link in one step, link in parts
the deb would depend on libgflags2, but the static lib is the only thing installed by make install
the following lines are in sorted order, FYI
the next one goes into the "base_compile" arg list
the refspec ensures that the default upstream branch gets updated
the version number of the release.
these should match the names found at http://www.debian.org/releases/
this is a CentOS7 or RHEL7 system
this is windows use the .zip and .exe extentions for the files.
this should always match the template from CONTRIBUTING.md
this should match the name found at http://releases.tanglu.org/
this should match the name found at http://releases.ubuntu.com/
to restore locales later: yum reinstall glibc-common
together with all shared library dependencies to that folder.
travis venv tests override python
try without the -e arg to sed.
udev doesn't work in containers, rebuild /dev
undef DEBUG if defined DEBUGWRAPPER define DEBUG(format, ...) fprintf(stderr, format, __VA_ARGS__) else define DEBUG(format, ...) endif
update bower.json tag each repo
update the snapshot folder
usage: just run this script (after having run build.sh) and deploy the created tarball to your target machine.
use "env -i" to tightly control the environment variables that bleed into the tests
use Intel SSE support for checksum calculations
use a copy to escape special characters, as we want to return the original.
use an up-to-date pip / setuptools inside the venv
use dlname if we got it.
use the github repo as it is more up to date than the svn repo
used as fallback echo
used for prog,scan pass
v2.1 or older doesn't pass the debug build but OK with release build
version is not provided, use latest
we can't check for "0.0" in archive_cmds due to quoting problems, so we reset it completely
we cannot install brewed git if homebrew/core is unavailable.
we do not want to link against static libs, but need to link against shared
we need to force mongo to use static library, not shared
we need to use file descriptor 10 because otherwise SSH will conflict with the while loop
we should really use a build-platform specific compiler here, but OTOH, the wrappers (shell script and this C one) are only useful if you want to execute the "real" binary.
we want to effectively run "apt-get clean" after every install to keep images small (see output of "apt-get clean -s" for context)
we're in a subshell, so this is safe -- our integration-cli tests need DEST, and "cd" screws it up
when two arguments are given, the first is prepended and the second appended to the state string when assigned to PS1.
whether we're linking any uninstalled libtool libraries
win32 will think the script is a binary if it has a .exe suffix, so we strip it off here.
write rate for readwhile...
write rate for tests other than readwhile, 0 means no limit
write_to_s3 uploads the contents of standard input to the specified S3 url.
yeah, this escaping is awful.
